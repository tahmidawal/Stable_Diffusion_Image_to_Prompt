{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Calculating prompt embeddings for the Stable Diffusion Competition\n\nThis notebook demonstrates how to the [sentence-transformers](https://github.com/UKPLab/sentence-transformers/) library to calculate sentence embeddings.\n [[docs](https://www.sbert.net/index.html)]\n\n\n**NOTE:** Since the re-run notebooks won't have internet access, you will need to attach the dataset [sentence-transformers-222](https://www.kaggle.com/datasets/inversion/sentence-transformers-222) to your notebooks to be able to install the Sentence Transformers library and access the `all-MiniLM-L6-v2` model used for encodings during the notebook re-run on the test data.","metadata":{}},{"cell_type":"code","source":"import sys\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\n\nsys.path.append('../input/sentence-transformers-222/sentence-transformers')\nfrom sentence_transformers import SentenceTransformer, models\n\ncomp_path = Path('/kaggle/input/stable-diffusion-image-to-prompts/')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-15T20:03:18.873138Z","iopub.execute_input":"2023-03-15T20:03:18.873588Z","iopub.status.idle":"2023-03-15T20:03:18.880599Z","shell.execute_reply.started":"2023-03-15T20:03:18.873547Z","shell.execute_reply":"2023-03-15T20:03:18.879171Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Actual prompts used for the images\n\n**NOTE:** This file will *not* be available for the notebook re-run. References to it will create notebook failures.","metadata":{}},{"cell_type":"code","source":"prompts = pd.read_csv(comp_path / 'prompts.csv', index_col='imgId')\nprompts.head(7)","metadata":{"execution":{"iopub.status.busy":"2023-03-15T20:06:05.734713Z","iopub.execute_input":"2023-03-15T20:06:05.735179Z","iopub.status.idle":"2023-03-15T20:06:05.755098Z","shell.execute_reply.started":"2023-03-15T20:06:05.735144Z","shell.execute_reply":"2023-03-15T20:06:05.753743Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                                      prompt\nimgId                                                       \n20057f34d  hyper realistic photo of very friendly and dys...\n227ef0887  ramen carved out of fractal rose ebony, in the...\n92e911621  ultrasaurus holding a black bean taco in the w...\na4e1c55a9  a thundering retro robot crane inks on parchme...\nc98f79f71  portrait painting of a shimmering greek hero, ...\nd8edf2e40  an astronaut standing on a engaging white rose...\nf27825b2c  Kaggle employee Phil at a donut shop ordering ...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n    </tr>\n    <tr>\n      <th>imgId</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>20057f34d</th>\n      <td>hyper realistic photo of very friendly and dys...</td>\n    </tr>\n    <tr>\n      <th>227ef0887</th>\n      <td>ramen carved out of fractal rose ebony, in the...</td>\n    </tr>\n    <tr>\n      <th>92e911621</th>\n      <td>ultrasaurus holding a black bean taco in the w...</td>\n    </tr>\n    <tr>\n      <th>a4e1c55a9</th>\n      <td>a thundering retro robot crane inks on parchme...</td>\n    </tr>\n    <tr>\n      <th>c98f79f71</th>\n      <td>portrait painting of a shimmering greek hero, ...</td>\n    </tr>\n    <tr>\n      <th>d8edf2e40</th>\n      <td>an astronaut standing on a engaging white rose...</td>\n    </tr>\n    <tr>\n      <th>f27825b2c</th>\n      <td>Kaggle employee Phil at a donut shop ordering ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## The Sample Submission contains correct embeddings (for the example images)\n\nThe `sample_submission.csv` file on the Data page has the correct imbeddings for the prompts listed in the `prompts.csv` file. This is so you can test whether you are calculating embeddings correctly.","metadata":{}},{"cell_type":"code","source":"import os\nif os.path.exists(\"../input/stable-diffusion-image-to-prompts/prompts.csv\"):\n    df_prompts = pd.read_csv(\"../input/stable-diffusion-image-to-prompts/prompts.csv\")\ndf_prompts","metadata":{"execution":{"iopub.status.busy":"2023-03-15T21:26:53.552794Z","iopub.execute_input":"2023-03-15T21:26:53.553232Z","iopub.status.idle":"2023-03-15T21:26:53.573182Z","shell.execute_reply.started":"2023-03-15T21:26:53.553193Z","shell.execute_reply":"2023-03-15T21:26:53.572255Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"       imgId                                             prompt\n0  20057f34d  hyper realistic photo of very friendly and dys...\n1  227ef0887  ramen carved out of fractal rose ebony, in the...\n2  92e911621  ultrasaurus holding a black bean taco in the w...\n3  a4e1c55a9  a thundering retro robot crane inks on parchme...\n4  c98f79f71  portrait painting of a shimmering greek hero, ...\n5  d8edf2e40  an astronaut standing on a engaging white rose...\n6  f27825b2c  Kaggle employee Phil at a donut shop ordering ...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>imgId</th>\n      <th>prompt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20057f34d</td>\n      <td>hyper realistic photo of very friendly and dys...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>227ef0887</td>\n      <td>ramen carved out of fractal rose ebony, in the...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>92e911621</td>\n      <td>ultrasaurus holding a black bean taco in the w...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>a4e1c55a9</td>\n      <td>a thundering retro robot crane inks on parchme...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>c98f79f71</td>\n      <td>portrait painting of a shimmering greek hero, ...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>d8edf2e40</td>\n      <td>an astronaut standing on a engaging white rose...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>f27825b2c</td>\n      <td>Kaggle employee Phil at a donut shop ordering ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Load the embedding model `all-MiniLM-L6-v2`\n\nThis model maps sentences to a 384 dimensional dense vector space. Load it from the [dataset](https://www.kaggle.com/datasets/inversion/sentence-transformers-222).","metadata":{}},{"cell_type":"code","source":"st_model = SentenceTransformer('/kaggle/input/sentence-transformers-222/all-MiniLM-L6-v2')","metadata":{"execution":{"iopub.status.busy":"2023-03-15T21:26:58.868417Z","iopub.execute_input":"2023-03-15T21:26:58.869801Z","iopub.status.idle":"2023-03-15T21:26:59.213062Z","shell.execute_reply.started":"2023-03-15T21:26:58.869756Z","shell.execute_reply":"2023-03-15T21:26:59.212152Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"## Calculate prompt embeddings","metadata":{}},{"cell_type":"code","source":"df_Y = st_model.encode(df_prompts['prompt']).flatten()","metadata":{"execution":{"iopub.status.busy":"2023-03-15T21:27:09.329361Z","iopub.execute_input":"2023-03-15T21:27:09.330739Z","iopub.status.idle":"2023-03-15T21:27:09.460446Z","shell.execute_reply.started":"2023-03-15T21:27:09.330691Z","shell.execute_reply":"2023-03-15T21:27:09.459140Z"},"trusted":true},"execution_count":42,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c500e9ddb774b8b9bbb52978d04c576"}},"metadata":{}}]},{"cell_type":"code","source":"df_Y[:7]","metadata":{"execution":{"iopub.status.busy":"2023-03-15T21:38:43.685137Z","iopub.execute_input":"2023-03-15T21:38:43.686590Z","iopub.status.idle":"2023-03-15T21:38:43.695190Z","shell.execute_reply.started":"2023-03-15T21:38:43.686541Z","shell.execute_reply":"2023-03-15T21:38:43.693672Z"},"trusted":true},"execution_count":63,"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"array([ 0.01884852,  0.03018975,  0.07279224, -0.00067344,  0.01677445,\n       -0.11378008, -0.03121929], dtype=float32)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Compare calculated embeddings with ground truth (within tolerance)","metadata":{}},{"cell_type":"code","source":"assert np.all(np.isclose(sample_submission['val'].values, prompt_embeddings, atol=1e-07))","metadata":{"execution":{"iopub.status.busy":"2023-03-15T21:27:24.909511Z","iopub.execute_input":"2023-03-15T21:27:24.910619Z","iopub.status.idle":"2023-03-15T21:27:24.916991Z","shell.execute_reply.started":"2023-03-15T21:27:24.910571Z","shell.execute_reply":"2023-03-15T21:27:24.915748Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"# **Function to load images and then flatten them to put in the dataFrame**","metadata":{}},{"cell_type":"code","source":"def image_id2path(\n    img_id: str, \n    folder: str = \"stable-diffusion-image-to-prompts\"\n) -> str:\n    return f\"../input/{folder}/images/{img_id}.png\"","metadata":{"execution":{"iopub.status.busy":"2023-03-15T21:27:29.610832Z","iopub.execute_input":"2023-03-15T21:27:29.611233Z","iopub.status.idle":"2023-03-15T21:27:29.616989Z","shell.execute_reply.started":"2023-03-15T21:27:29.611197Z","shell.execute_reply":"2023-03-15T21:27:29.616107Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\n\n# DataFrame with X data\ndf_X = []\nfor _, row in df_prompts[:7].iterrows():\n    img_id = row[\"imgId\"]\n    prompt = row[\"prompt\"]\n    path = image_id2path(img_id, \"stable-diffusion-image-to-prompts\")\n    image = cv2.imread(path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n    df_X.append(image.flatten())","metadata":{"execution":{"iopub.status.busy":"2023-03-15T21:38:19.404334Z","iopub.execute_input":"2023-03-15T21:38:19.404759Z","iopub.status.idle":"2023-03-15T21:38:19.517940Z","shell.execute_reply.started":"2023-03-15T21:38:19.404724Z","shell.execute_reply":"2023-03-15T21:38:19.516860Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"df_X","metadata":{"execution":{"iopub.status.busy":"2023-03-15T21:38:27.489429Z","iopub.execute_input":"2023-03-15T21:38:27.489851Z","iopub.status.idle":"2023-03-15T21:38:27.498585Z","shell.execute_reply.started":"2023-03-15T21:38:27.489812Z","shell.execute_reply":"2023-03-15T21:38:27.497171Z"},"trusted":true},"execution_count":62,"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"[array([143, 135, 132, ...,  56,  68,  78], dtype=uint8),\n array([167, 174, 181, ..., 168, 172, 177], dtype=uint8),\n array([ 93, 125,  56, ..., 157, 205,  60], dtype=uint8),\n array([71, 70, 56, ...,  1,  0,  1], dtype=uint8),\n array([167, 125,  80, ..., 110,  85,  69], dtype=uint8),\n array([121, 110,  97, ...,  30,  32,   8], dtype=uint8),\n array([110,  69,  71, ...,  85,  61,  45], dtype=uint8)]"},"metadata":{}}]},{"cell_type":"markdown","source":"### We have the df_X and df_Y provided by the test. However it seems like we will need to produce some more df_X from a stable diffusion model using the promts since all of them are not provided ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}